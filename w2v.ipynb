{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import six\n",
    "import numpy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_SIZE = 32      # embedding维度\n",
    "HIDDEN_SIZE = 256    # 隐层大小\n",
    "N = 5                # ngram大小，这里固定取5\n",
    "BATCH_SIZE = 100     # batch大小\n",
    "PASS_NUM = 100       # 训练轮数\n",
    "use_cuda = False  # 如果用GPU训练，则设置为True\n",
    "word_dict = paddle.dataset.imikolov.build_dict()\n",
    "dict_size = len(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_program(words, is_sparse):\n",
    "\n",
    "    embed_first = fluid.embedding(\n",
    "        input=words[0],\n",
    "        size=[dict_size, EMBED_SIZE],\n",
    "        dtype='float32',\n",
    "        is_sparse=is_sparse,\n",
    "        param_attr='shared_w')\n",
    "    embed_second = fluid.embedding(\n",
    "        input=words[1],\n",
    "        size=[dict_size, EMBED_SIZE],\n",
    "        dtype='float32',\n",
    "        is_sparse=is_sparse,\n",
    "        param_attr='shared_w')\n",
    "    embed_third = fluid.embedding(\n",
    "        input=words[2],\n",
    "        size=[dict_size, EMBED_SIZE],\n",
    "        dtype='float32',\n",
    "        is_sparse=is_sparse,\n",
    "        param_attr='shared_w')\n",
    "    embed_fourth = fluid.embedding(\n",
    "        input=words[3],\n",
    "        size=[dict_size, EMBED_SIZE],\n",
    "        dtype='float32',\n",
    "        is_sparse=is_sparse,\n",
    "        param_attr='shared_w')\n",
    "\n",
    "    concat_embed = fluid.layers.concat(\n",
    "        input=[embed_first, embed_second, embed_third, embed_fourth], axis=1)\n",
    "    hidden1 = fluid.layers.fc(input=concat_embed,\n",
    "                              size=HIDDEN_SIZE,\n",
    "                              act='sigmoid')\n",
    "    predict_word = fluid.layers.fc(input=hidden1, size=dict_size, act='softmax')\n",
    "    return predict_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_program(predict_word):\n",
    "    # 'next_word'的定义必须要在inference_program的声明之后，\n",
    "    # 否则train program输入数据的顺序就变成了[next_word, firstw, secondw,\n",
    "    # thirdw, fourthw], 这是不正确的.\n",
    "    next_word = fluid.data(name='nextw', shape=[None, 1], dtype='int64')\n",
    "    cost = fluid.layers.cross_entropy(input=predict_word, label=next_word)\n",
    "    avg_cost = fluid.layers.mean(cost)\n",
    "    return avg_cost\n",
    "\n",
    "def optimizer_func():\n",
    "    return fluid.optimizer.AdagradOptimizer(\n",
    "        learning_rate=3e-3,\n",
    "        regularization=fluid.regularizer.L2DecayRegularizer(8e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(if_use_cuda, params_dirname, is_sparse=True):\n",
    "    place = fluid.CUDAPlace(0) if if_use_cuda else fluid.CPUPlace()\n",
    "\n",
    "    train_reader = paddle.batch(\n",
    "        paddle.dataset.imikolov.train(word_dict, N), BATCH_SIZE)\n",
    "    test_reader = paddle.batch(\n",
    "        paddle.dataset.imikolov.test(word_dict, N), BATCH_SIZE)\n",
    "\n",
    "    first_word = fluid.data(name='firstw', shape=[None, 1], dtype='int64')\n",
    "    second_word = fluid.data(name='secondw', shape=[None, 1], dtype='int64')\n",
    "    third_word = fluid.data(name='thirdw', shape=[None, 1], dtype='int64')\n",
    "    forth_word = fluid.data(name='fourthw', shape=[None, 1], dtype='int64')\n",
    "    next_word = fluid.data(name='nextw', shape=[None, 1], dtype='int64')\n",
    "\n",
    "    word_list = [first_word, second_word, third_word, forth_word, next_word]\n",
    "    feed_order = ['firstw', 'secondw', 'thirdw', 'fourthw', 'nextw']\n",
    "\n",
    "    main_program = fluid.default_main_program()\n",
    "    star_program = fluid.default_startup_program()\n",
    "\n",
    "    predict_word = inference_program(word_list, is_sparse)\n",
    "    avg_cost = train_program(predict_word)\n",
    "    test_program = main_program.clone(for_test=True)\n",
    "\n",
    "    sgd_optimizer = optimizer_func()\n",
    "    sgd_optimizer.minimize(avg_cost)\n",
    "\n",
    "    exe = fluid.Executor(place)\n",
    "\n",
    "    def train_test(program, reader):\n",
    "        count = 0\n",
    "        feed_var_list = [\n",
    "            program.global_block().var(var_name) for var_name in feed_order\n",
    "        ]\n",
    "        feeder_test = fluid.DataFeeder(feed_list=feed_var_list, place=place)\n",
    "        test_exe = fluid.Executor(place)\n",
    "        accumulated = len([avg_cost]) * [0]\n",
    "        for test_data in reader():\n",
    "            avg_cost_np = test_exe.run(\n",
    "                program=program,\n",
    "                feed=feeder_test.feed(test_data),\n",
    "                fetch_list=[avg_cost])\n",
    "            accumulated = [\n",
    "                x[0] + x[1][0] for x in zip(accumulated, avg_cost_np)\n",
    "            ]\n",
    "            count += 1\n",
    "        return [x / count for x in accumulated]\n",
    "\n",
    "    def train_loop():\n",
    "        step = 0\n",
    "        feed_var_list_loop = [\n",
    "            main_program.global_block().var(var_name) for var_name in feed_order\n",
    "        ]\n",
    "        feeder = fluid.DataFeeder(feed_list=feed_var_list_loop, place=place)\n",
    "        exe.run(star_program)\n",
    "        for pass_id in range(PASS_NUM):\n",
    "            for data in train_reader():\n",
    "                avg_cost_np = exe.run(\n",
    "                    main_program, feed=feeder.feed(data), fetch_list=[avg_cost])\n",
    "\n",
    "                if step % 10 == 0:\n",
    "                    outs = train_test(test_program, test_reader)\n",
    "\n",
    "                    print(\"Step %d: Average Cost %f\" % (step, outs[0]))\n",
    "\n",
    "                    # 整个训练过程要花费几个小时，如果平均损失低于5.8，\n",
    "                    # 我们就认为模型已经达到很好的效果可以停止训练了。\n",
    "                    # 注意5.8是一个相对较高的值，为了获取更好的模型，可以将\n",
    "                    # 这里的阈值设为3.5，但训练时间也会更长。\n",
    "                    if outs[0] < 5.8:\n",
    "                        if params_dirname is not None:\n",
    "                            fluid.io.save_inference_model(params_dirname, [\n",
    "                                'firstw', 'secondw', 'thirdw', 'fourthw'\n",
    "                            ], [predict_word], exe)\n",
    "                        return\n",
    "                step += 1\n",
    "                if math.isnan(float(avg_cost_np[0])):\n",
    "                    sys.exit(\"got NaN loss, training failed.\")\n",
    "\n",
    "        raise AssertionError(\"Cost is too large {0:2.2}\".format(avg_cost_np[0]))\n",
    "\n",
    "    train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(use_cuda, params_dirname=None):\n",
    "    place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\n",
    "\n",
    "    exe = fluid.Executor(place)\n",
    "\n",
    "    inference_scope = fluid.core.Scope()\n",
    "    with fluid.scope_guard(inference_scope):\n",
    "        # 使用fluid.io.load_inference_model获取inference program，\n",
    "        # feed变量的名称feed_target_names和从scope中fetch的对象fetch_targets\n",
    "        [inferencer, feed_target_names,\n",
    "         fetch_targets] = fluid.io.load_inference_model(params_dirname, exe)\n",
    "\n",
    "        # 设置输入，用四个LoDTensor来表示4个词语。这里每个词都是一个id，\n",
    "        # 用来查询embedding表获取对应的词向量，因此其形状大小是[1]。\n",
    "        # recursive_sequence_lengths设置的是基于长度的LoD，因此都应该设为[[1]]\n",
    "        # 注意recursive_sequence_lengths是列表的列表\n",
    "        data1 = numpy.asarray([[211]], dtype=numpy.int64)  # 'among'\n",
    "        data2 = numpy.asarray([[6]], dtype=numpy.int64)  # 'a'\n",
    "        data3 = numpy.asarray([[96]], dtype=numpy.int64)  # 'group'\n",
    "        data4 = numpy.asarray([[4]], dtype=numpy.int64)  # 'of'\n",
    "        lod = numpy.asarray([[1]], dtype=numpy.int64)\n",
    "\n",
    "        first_word = fluid.create_lod_tensor(data1, lod, place)\n",
    "        second_word = fluid.create_lod_tensor(data2, lod, place)\n",
    "        third_word = fluid.create_lod_tensor(data3, lod, place)\n",
    "        fourth_word = fluid.create_lod_tensor(data4, lod, place)\n",
    "\n",
    "        assert feed_target_names[0] == 'firstw'\n",
    "        assert feed_target_names[1] == 'secondw'\n",
    "        assert feed_target_names[2] == 'thirdw'\n",
    "        assert feed_target_names[3] == 'fourthw'\n",
    "\n",
    "        # 构造feed词典 {feed_target_name: feed_target_data}\n",
    "        # 预测结果包含在results之中\n",
    "        results = exe.run(\n",
    "            inferencer,\n",
    "            feed={\n",
    "                feed_target_names[0]: first_word,\n",
    "                feed_target_names[1]: second_word,\n",
    "                feed_target_names[2]: third_word,\n",
    "                feed_target_names[3]: fourth_word\n",
    "            },\n",
    "            fetch_list=fetch_targets,\n",
    "            return_numpy=False)\n",
    "\n",
    "        print(numpy.array(results[0]))\n",
    "        most_possible_word_index = numpy.argmax(results[0])\n",
    "        print(most_possible_word_index)\n",
    "        print([\n",
    "            key for key, value in six.iteritems(word_dict)\n",
    "            if value == most_possible_word_index\n",
    "        ][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Average Cost 7.394525\n",
      "Step 10: Average Cost 6.189804\n",
      "Step 20: Average Cost 5.843170\n",
      "Step 30: Average Cost 5.709286\n",
      "[[0.04577721 0.0331917  0.03833447 ... 0.0001859  0.00015016 0.03313617]]\n",
      "0\n",
      "b'the'\n"
     ]
    }
   ],
   "source": [
    "def main(use_cuda, is_sparse):\n",
    "    if use_cuda and not fluid.core.is_compiled_with_cuda():\n",
    "        return\n",
    "\n",
    "    params_dirname = \"word2vec.inference.model\"\n",
    "\n",
    "    train(\n",
    "        if_use_cuda=use_cuda,\n",
    "        params_dirname=params_dirname,\n",
    "        is_sparse=is_sparse)\n",
    "\n",
    "    infer(use_cuda=use_cuda, params_dirname=params_dirname)\n",
    "\n",
    "main(use_cuda=use_cuda, is_sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
